#t cannot find suitable ports
spark.port.maxRetries=100
 
# To throttle your total impact on the cluster. Maximum amount of cores to be claimed by your process in total.
spark.cores.max=50
 
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max=1524
 
spark.driver.extraLibraryPath=/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.driver.extraJavaOptions=-XX:+UseG1GC
spark.driver.memory=18g
spark.driver.cores=8
 
spark.eventLog.dir=hdfs:///spark2-history/
spark.eventLog.enabled=true
 
spark.executorEnv.PYTHONHASHSEED=123
 
spark.history.fs.cleaner.enabled=true
spark.history.fs.cleaner.interval=1d
spark.history.fs.cleaner.maxAge=7d
spark.history.fs.logDirectory=hdfs:///spark2-history/
spark.history.kerberos.enabled=true
spark.history.kerberos.keytab=keytab_file
spark.history.kerberos.principal=principal_kerberos_link
spark.history.provider=org.apache.spark.deploy.history.FsHistoryProvider
spark.history.ui.port=18081
 
 
# Important: the default queue has changed and we need to use this queue to acquire enough resources.
spark.yarn.queue=Batch-Prd-BLG
spark.yarn.historyServer.address=klm_hadoop_cluster:18081
 
# Driver and executor memory overhead. This is the allowed memory overflow on top of the maximum memory.
spark.driver.memoryOverhead=8g
spark.executor.memoryOverhead=8g
 
# Maximum number of parallel workers for Spark. This determines your primary degree of parallelism.
spark.dynamicAllocation.maxExecutors=20
spark.dynamicAllocation.initialExecutors=4
 
spark.dynamicAllocation.minExecutors=4
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60
spark.dynamicAllocation.cachedExecutorIdleTimeout=900
 
# Number of processing cores per worker. Total amount of memory claimed per worker is executor.cores * executor.memory.
spark.executor.cores=4
spark.executor.memory=16g
spark.executor.extraLibraryPath=/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.executor.extraJavaOptions=-XX:+UseG1GC
 
spark.shuffle.service.enabled=true
 
spark.sql.autoBroadcastJoinThreshold=-1
